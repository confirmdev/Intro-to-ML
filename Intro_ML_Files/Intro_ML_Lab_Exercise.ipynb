{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CLASSIFICATION PROBLEM (SKLEARN APPLIED ON PROJECT DATA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LOGISTIC REGRESSION**\n",
    "\n",
    "We will apply logistic regression from sklearn to the project data to classify data into the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 13)\n",
      "(231, 13)\n"
     ]
    }
   ],
   "source": [
    "# read in the project data (train and test)\n",
    "train_data = pd.read_csv('train_data.txt', header=None)\n",
    "# read train data\n",
    "\n",
    "\n",
    "# read test data\n",
    "test_data = pd.read_csv('test_data.txt', header=None)\n",
    "\n",
    "# display shape of train data\n",
    "print(train.shape)\n",
    "# display shape of test data\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.364042</td>\n",
       "      <td>0.680010</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.668446</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>0.355260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.502017</td>\n",
       "      <td>0.270471</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.344367</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449798</td>\n",
       "      <td>0.572941</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.481580</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>0.228560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102993</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.763481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.459788</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.342766</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>0.232766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   0  0.521037  0.022658  0.545989  0.364042  0.680010  0.792037  0.703140   \n",
       "1   1  0.643144  0.272574  0.615783  0.502017  0.270471  0.181768  0.203608   \n",
       "2   2  0.601496  0.390260  0.595743  0.449798  0.572941  0.431017  0.462512   \n",
       "3   3  0.210090  0.360839  0.233501  0.102993  0.973233  0.811361  0.565604   \n",
       "4   4  0.629893  0.156578  0.630986  0.489705  0.459788  0.347893  0.463918   \n",
       "\n",
       "         8         9         10        11  12  \n",
       "0  0.731113  0.668446  0.605518  0.355260   1  \n",
       "1  0.348757  0.344367  0.141323  0.155274   1  \n",
       "2  0.635686  0.481580  0.211247  0.228560   1  \n",
       "3  0.522863  0.763481  1.000000  0.137905   1  \n",
       "4  0.518390  0.342766  0.186816  0.232766   1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display 5 rows in train\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.119570</td>\n",
       "      <td>0.334175</td>\n",
       "      <td>0.118650</td>\n",
       "      <td>0.060242</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.092786</td>\n",
       "      <td>0.561570</td>\n",
       "      <td>0.282460</td>\n",
       "      <td>0.061753</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801815</td>\n",
       "      <td>0.674407</td>\n",
       "      <td>0.771190</td>\n",
       "      <td>0.676478</td>\n",
       "      <td>0.489934</td>\n",
       "      <td>0.406387</td>\n",
       "      <td>0.634938</td>\n",
       "      <td>0.737062</td>\n",
       "      <td>0.498647</td>\n",
       "      <td>0.099978</td>\n",
       "      <td>0.368507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.341072</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.332638</td>\n",
       "      <td>0.202008</td>\n",
       "      <td>0.405164</td>\n",
       "      <td>0.348902</td>\n",
       "      <td>0.220275</td>\n",
       "      <td>0.220753</td>\n",
       "      <td>0.576455</td>\n",
       "      <td>0.300376</td>\n",
       "      <td>0.097557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.097065</td>\n",
       "      <td>0.299344</td>\n",
       "      <td>0.098719</td>\n",
       "      <td>0.047241</td>\n",
       "      <td>0.290512</td>\n",
       "      <td>0.262595</td>\n",
       "      <td>0.231692</td>\n",
       "      <td>0.119812</td>\n",
       "      <td>0.660352</td>\n",
       "      <td>0.458084</td>\n",
       "      <td>0.029932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.170764</td>\n",
       "      <td>0.204442</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.457434</td>\n",
       "      <td>0.257365</td>\n",
       "      <td>0.148473</td>\n",
       "      <td>0.174647</td>\n",
       "      <td>0.484438</td>\n",
       "      <td>0.409865</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "0   0  0.119570  0.334175  0.118650  0.060242  0.433962  0.186667  0.069078   \n",
       "1   1  0.801815  0.674407  0.771190  0.676478  0.489934  0.406387  0.634938   \n",
       "2   2  0.341072  0.284200  0.332638  0.202008  0.405164  0.348902  0.220275   \n",
       "3   3  0.097065  0.299344  0.098719  0.047241  0.290512  0.262595  0.231692   \n",
       "4   4  0.170764  0.204442  0.169593  0.087317  0.457434  0.257365  0.148473   \n",
       "\n",
       "         8         9         10        11  12  \n",
       "0  0.092786  0.561570  0.282460  0.061753   2  \n",
       "1  0.737062  0.498647  0.099978  0.368507   1  \n",
       "2  0.220753  0.576455  0.300376  0.097557   2  \n",
       "3  0.119812  0.660352  0.458084  0.029932   2  \n",
       "4  0.174647  0.484438  0.409865  0.019955   2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display 5 rows in train\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-bad16dddfea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remove the first column  named 0 in both train and test data and overwrite the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4162\u001b[0m         \"\"\"\n\u001b[0;32m-> 4163\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5282\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0] not found in axis'"
     ]
    }
   ],
   "source": [
    "# remove the first column  named 0 in both train and test data and overwrite the data\n",
    "train_data.drop(0, inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.502017</td>\n",
       "      <td>0.270471</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.344367</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449798</td>\n",
       "      <td>0.572941</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.481580</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>0.228560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102993</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.763481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.459788</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.342766</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>0.232766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.258839</td>\n",
       "      <td>0.202570</td>\n",
       "      <td>0.267984</td>\n",
       "      <td>0.141626</td>\n",
       "      <td>0.794379</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>0.369728</td>\n",
       "      <td>0.402038</td>\n",
       "      <td>0.491191</td>\n",
       "      <td>0.551179</td>\n",
       "      <td>0.079487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7   \\\n",
       "1   1  0.643144  0.272574  0.615783  0.502017  0.270471  0.181768  0.203608   \n",
       "2   2  0.601496  0.390260  0.595743  0.449798  0.572941  0.431017  0.462512   \n",
       "3   3  0.210090  0.360839  0.233501  0.102993  0.973233  0.811361  0.565604   \n",
       "4   4  0.629893  0.156578  0.630986  0.489705  0.459788  0.347893  0.463918   \n",
       "5   5  0.258839  0.202570  0.267984  0.141626  0.794379  0.461996  0.369728   \n",
       "\n",
       "         8         9         10        11  12  \n",
       "1  0.348757  0.344367  0.141323  0.155274   1  \n",
       "2  0.635686  0.481580  0.211247  0.228560   1  \n",
       "3  0.522863  0.763481  1.000000  0.137905   1  \n",
       "4  0.518390  0.342766  0.186816  0.232766   1  \n",
       "5  0.402038  0.491191  0.551179  0.079487   1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 13 elements, new values have 12 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-cde989aff553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# assign the following names to the columns of both the train and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'Group1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group6'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group9'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Group11'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5151\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5153\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5154\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 13 elements, new values have 12 elements"
     ]
    }
   ],
   "source": [
    "# assign the following names to the columns of both the train and test data\n",
    "column_names =  ['Group1','Group2','Group3','Group4','Group5','Group6','Group7','Group8','Group9','Group10','Group11','Class']\n",
    "train_data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>Group3</th>\n",
       "      <th>Group4</th>\n",
       "      <th>Group5</th>\n",
       "      <th>Group6</th>\n",
       "      <th>Group7</th>\n",
       "      <th>Group8</th>\n",
       "      <th>Group9</th>\n",
       "      <th>Group10</th>\n",
       "      <th>Group11</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.364042</td>\n",
       "      <td>0.680010</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.668446</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>0.355260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.502017</td>\n",
       "      <td>0.270471</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.344367</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449798</td>\n",
       "      <td>0.572941</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.481580</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>0.228560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102993</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.763481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.459788</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.342766</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>0.232766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group1    Group2    Group3    Group4    Group5    Group6    Group7  \\\n",
       "0  0.521037  0.022658  0.545989  0.364042  0.680010  0.792037  0.703140   \n",
       "1  0.643144  0.272574  0.615783  0.502017  0.270471  0.181768  0.203608   \n",
       "2  0.601496  0.390260  0.595743  0.449798  0.572941  0.431017  0.462512   \n",
       "3  0.210090  0.360839  0.233501  0.102993  0.973233  0.811361  0.565604   \n",
       "4  0.629893  0.156578  0.630986  0.489705  0.459788  0.347893  0.463918   \n",
       "\n",
       "     Group8    Group9   Group10   Group11  Class  \n",
       "0  0.731113  0.668446  0.605518  0.355260      1  \n",
       "1  0.348757  0.344367  0.141323  0.155274      1  \n",
       "2  0.635686  0.481580  0.211247  0.228560      1  \n",
       "3  0.522863  0.763481  1.000000  0.137905      1  \n",
       "4  0.518390  0.342766  0.186816  0.232766      1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that names have been properly assigned by displaying first 5 rows of train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>Group3</th>\n",
       "      <th>Group4</th>\n",
       "      <th>Group5</th>\n",
       "      <th>Group6</th>\n",
       "      <th>Group7</th>\n",
       "      <th>Group8</th>\n",
       "      <th>Group9</th>\n",
       "      <th>Group10</th>\n",
       "      <th>Group11</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119570</td>\n",
       "      <td>0.334175</td>\n",
       "      <td>0.118650</td>\n",
       "      <td>0.060242</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.092786</td>\n",
       "      <td>0.561570</td>\n",
       "      <td>0.282460</td>\n",
       "      <td>0.061753</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.801815</td>\n",
       "      <td>0.674407</td>\n",
       "      <td>0.771190</td>\n",
       "      <td>0.676478</td>\n",
       "      <td>0.489934</td>\n",
       "      <td>0.406387</td>\n",
       "      <td>0.634938</td>\n",
       "      <td>0.737062</td>\n",
       "      <td>0.498647</td>\n",
       "      <td>0.099978</td>\n",
       "      <td>0.368507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341072</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.332638</td>\n",
       "      <td>0.202008</td>\n",
       "      <td>0.405164</td>\n",
       "      <td>0.348902</td>\n",
       "      <td>0.220275</td>\n",
       "      <td>0.220753</td>\n",
       "      <td>0.576455</td>\n",
       "      <td>0.300376</td>\n",
       "      <td>0.097557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097065</td>\n",
       "      <td>0.299344</td>\n",
       "      <td>0.098719</td>\n",
       "      <td>0.047241</td>\n",
       "      <td>0.290512</td>\n",
       "      <td>0.262595</td>\n",
       "      <td>0.231692</td>\n",
       "      <td>0.119812</td>\n",
       "      <td>0.660352</td>\n",
       "      <td>0.458084</td>\n",
       "      <td>0.029932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170764</td>\n",
       "      <td>0.204442</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.087317</td>\n",
       "      <td>0.457434</td>\n",
       "      <td>0.257365</td>\n",
       "      <td>0.148473</td>\n",
       "      <td>0.174647</td>\n",
       "      <td>0.484438</td>\n",
       "      <td>0.409865</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group1    Group2    Group3    Group4    Group5    Group6    Group7  \\\n",
       "0  0.119570  0.334175  0.118650  0.060242  0.433962  0.186667  0.069078   \n",
       "1  0.801815  0.674407  0.771190  0.676478  0.489934  0.406387  0.634938   \n",
       "2  0.341072  0.284200  0.332638  0.202008  0.405164  0.348902  0.220275   \n",
       "3  0.097065  0.299344  0.098719  0.047241  0.290512  0.262595  0.231692   \n",
       "4  0.170764  0.204442  0.169593  0.087317  0.457434  0.257365  0.148473   \n",
       "\n",
       "     Group8    Group9   Group10   Group11  Class  \n",
       "0  0.092786  0.561570  0.282460  0.061753      2  \n",
       "1  0.737062  0.498647  0.099978  0.368507      1  \n",
       "2  0.220753  0.576455  0.300376  0.097557      2  \n",
       "3  0.119812  0.660352  0.458084  0.029932      2  \n",
       "4  0.174647  0.484438  0.409865  0.019955      2  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that names have been properly assigned by displaying first 5 rows of test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform some data explorations on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9c26495413fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "sb.pairplot(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the distribution of target in the train data\n",
    "plt.figure(figsize=(6,6))\n",
    "total = float(len(train_data))\n",
    "ax = sb.countplot(train_data['Class'],palette='bwr')\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:.2f}%'.format((height/total)*100),ha=\"center\") \n",
    "plt.xticks(rotation=45)\n",
    "t = plt.title(\"Count plot of Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train data into features and target\n",
    "\n",
    "# separate test data into features and target as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split train data in train and validation\n",
    "# proj_train, proj_valid,y_proj_train,y_proj_valid = train_test_split(X,y,test_size = 0.2, random_state = 100)\n",
    "# print(proj_train.shape)\n",
    "# print(y_proj_train.shape)\n",
    "# print(proj_valid.shape)\n",
    "# print(y_proj_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logistic module\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "\n",
    "# train model by fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2,\n",
       "       2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2,\n",
       "       1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2,\n",
       "       1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1,\n",
       "       1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "log_predictions = logistic_model.predict(test_features)\n",
    "# display all the predictions made\n",
    "log_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate logistic mode performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9047619047619048\n",
      "precision_score: 0.717948717948718\n",
      "recall_score: 1.0\n",
      "f1_score: 0.835820895522388\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy_score: {accuracy_score(test_target,log_predictions)}')\n",
    "print(f'precision_score: {precision_score(test_target,log_predictions)}')\n",
    "print(f'recall_score: {recall_score(test_target,log_predictions)}')\n",
    "print(f'f1_score: {f1_score(test_target,log_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+=++=++=++=++=++=++=++=++=++=++=++=++=++=++=++=++=++=+\n",
      "+=++=++=++=+ Classification Report Project Data +=++=+\n",
      "+=++=++=++=++=++=++=++=++=++=++=++=++=++=++=++=++=++=+\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      1.00      0.84        56\n",
      "           2       1.00      0.87      0.93       175\n",
      "\n",
      "    accuracy                           0.90       231\n",
      "   macro avg       0.86      0.94      0.88       231\n",
      "weighted avg       0.93      0.90      0.91       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "target_names = ['1','2']\n",
    "conf_mat = confusion_matrix(test_target,log_predictions)\n",
    "f,ax= plt.subplots(1,1,figsize=(7,6))\n",
    "sb.heatmap(conf_mat,annot=True,fmt='.0f',cmap='icefire', ax = ax,annot_kws={\"size\":18})\n",
    "ax.set_xticklabels(target_names,fontsize = 15)\n",
    "ax.set_yticklabels(target_names,fontsize = 15)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix Logistic Regression');\n",
    "plt.show()\n",
    "\n",
    "print('+=+'*18)\n",
    "print('+=++=++=++=+ Classification Report Project Data'+' '+'+=++=+')\n",
    "print('+=+'*18)\n",
    "print(classification_report(test_target, log_predictions,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Confusion Matrix:** a table showing correct predictions and types of incorrect predictions.\n",
    "\n",
    "- **Precision:** the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifiers exactness. Low precision indicates a high number of false positives.\n",
    "\n",
    "- **Recall:** the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifiers completeness. Low recall indicates a high number of false negatives.\n",
    "\n",
    "- **F1 Score:** the weighted average of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can improve the above model by applying the concept of hyperparameter tuning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HYPERPARAMETERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters are tuning measures that are specified for a model before training. Each type of model has its own unique set of hyperparameters. \n",
    "\n",
    "Oftentimes, the base function has defaults for these hyperparameters when they are not specified. So, it is always important to check the documentation on each model to know the complete list of hyperparameters that can be tuned.\n",
    "\n",
    "Now that we know the corresponding hyperparameters to tune for our model, the problem now is, how do we combine these hyperparameters to know which combination will give us the best performance for our data?\n",
    "\n",
    "**RESPONSE**\n",
    "\n",
    "There is a super easy way to do this using three functions in scikit-learn.\n",
    "\n",
    "* GridSearchCV\n",
    "\n",
    "* RandomizedSearchCV\n",
    "\n",
    "* Pipeline (feeds list of diff models and their hyperparameters to a grid or randomized search)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's use use gridsearch to finetune our linear regression model\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# # create list of candidate penalty hyperparameters\n",
    "# penalty = ['l1','l2']\n",
    "\n",
    "# # create range of candidate regularization hyperparameters\n",
    "# C = np.logspace(0,4,10)\n",
    "\n",
    "# # create a dictionary hyperparameter candidates\n",
    "# hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# # create a grid search object and pass in the hyperparameters defined\n",
    "# gridsearch = GridSearchCV(model, hyperparameters, cv=5,verbose=1)\n",
    "\n",
    "# # fitting the data to the grid for searching\n",
    "# bestmodel = gridsearch.fit(train_features,train_target)\n",
    "\n",
    "# # let's see the best hyperparameter values for the best model\n",
    "# print(bestmodel.best_estimator_.get_params())\n",
    "# print('')\n",
    "# # mean accuracy for the best model\n",
    "# print(bestmodel.score(train_features,train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "**RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's use use gridsearch to finetune our logistic regression model\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# # create list of candidate penalty hyperparameters\n",
    "# penalty = ['l1','l2']\n",
    "\n",
    "# # create range of candidate regularization hyperparameters\n",
    "# C = uniform(0,4)\n",
    "\n",
    "# # create a dictionary hyperparameter candidates\n",
    "# hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# # create a grid search object and pass in the hyperparameters defined\n",
    "# randomzedsearch = RandomizedSearchCV(model, hyperparameters, cv=5,verbose=1,n_iter=100,random_state=1)\n",
    "\n",
    "# # fitting the data to the grid for searching\n",
    "# bestmodel1 = randomzedsearch.fit(train_features,train_target)\n",
    "\n",
    "# # let's see the best hyperparameter values for the best model\n",
    "# print(bestmodel1.best_estimator_.get_params())\n",
    "\n",
    "# # mean accuracy for the best model\n",
    "# print(bestmodel1.score(train_features,train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# **RESOURCE MATERIALS FOR FURTHER READING**\n",
    "\n",
    "* MIT Free Online Course on **[INTRODUCTION TO MACHINE LEARNING](https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/course/)**.\n",
    "\n",
    "* Free Course by Google Developers **[MACHINE LEARN CRASH](https://developers.google.com/machine-learning/crash-course).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ASSIGNMENT**:\n",
    "\n",
    "* Please answer the under-listed questions using an overleaf template (please visit this [link](https://www.overleaf.com/learn/how-to/Creating_a_document_in_Overleaf) for a brief tutorial on how to create a document with overleaf).**\n",
    "\n",
    "* You are reminded that all these questions can be obtained from this [website](https://www.mygreatlearning.com/blog/machine-learning-interview-questions/). You can reference it as a guide, but do not attempt to copy anything from there. Failure to comply with this will result in severe consequences.**\n",
    "\n",
    "* **Each question carries a single point i.e. 4 points...Total Score: 100 points**\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "### **ANSWER AS MANY AS YOU CAN**\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "1. What is the main key difference between supervised and unsupervised machine learning?\n",
    "\n",
    "2. What is Linear Regression?\n",
    "\n",
    "3. List all assumptions for data to be met before starting with linear regression.\n",
    "\n",
    "4. Differentiate between regression and classification.\n",
    "\n",
    "5. Explain the difference between Normalization and Standardization.\n",
    "\n",
    "6. Why is logistic regression a type of classification technique and not a regression? Name the function it is derived from? \n",
    "\n",
    "7. Explain the phrase Curse of Dimensionality.\n",
    "\n",
    "8. Whats a Fourier transform?\n",
    "\n",
    "9. What is a confusion matrix and why do you need it?\n",
    "\n",
    "10. What is the Principle Component Analysis?\n",
    "\n",
    "11. What is the difference between regularization and normalisation? \n",
    "\n",
    "12. List the most popular distribution curves along with scenarios where you will use them in an algorithm.\n",
    "\n",
    "13. Can you mention some advantages and disadvantages of decision trees?\n",
    "\n",
    "14. What is the exploding gradient problem while using back propagation technique?\n",
    "\n",
    "15. What is the difference between stochastic gradient descent (SGD) and gradient descent (GD)?\n",
    "\n",
    "16. When does regularization come into play in Machine Learning?\n",
    "\n",
    "17. What is overfitting?\n",
    "\n",
    "18. Explain One-hot encoding and Label Encoding. How do they affect the dimensionality of the given dataset?\n",
    "\n",
    "19. There are many machine learning algorithms till now. If given a data set, how can one determine which algorithm to be used for that?\n",
    "\n",
    "20. How do you select important variables while working on a data set? \n",
    "\n",
    "21. What is the difference between deep learning and machine learning?\n",
    "\n",
    "22. What are the different types of Learning/ Training models in ML?\n",
    "\n",
    "23. Explain the terms Artificial Intelligence (AI), Machine Learning (ML and Deep Learning?\n",
    "\n",
    "24. How are covariance and correlation different from one another?\n",
    "\n",
    "25. State the differences between causality and correlation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
